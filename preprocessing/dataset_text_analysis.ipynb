{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_results = \"../results/reddit_results/\"\n",
    "text_data = \"../text_data/\"\n",
    "\n",
    "categories = [\"guncontrol\", 'minority', \"politics\"]\n",
    "semesters = [('01/01/2017','01/07/2017'), ('01/07/2017','01/01/2018'),\n",
    "             ('01/01/2018','01/07/2018'), ('01/07/2018','01/01/2019'), ('01/01/2019','01/07/2019')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_comments(cat, ec_val):\n",
    "    data_path = f\"../data\" \n",
    "    for topic in tqdm(categories):\n",
    "        i = 0\n",
    "        for sem in semesters:\n",
    "            print(\"Current iteration:\", i)\n",
    "        # prendiamo il df delle EC\n",
    "            df_EC = pd.read_csv(os.path.join(src_results, f\"{topic}/{ec_val}/{ec_val}_{topic}_{i}.csv\"))\n",
    "        # global community stats + users\n",
    "            df_users_original = pd.read_csv(os.path.join(src_results, f\"{topic}/eva_users_merged_{i}_com_stats.csv\"))\n",
    "            df_users = df_users_original[(df_users_original[\"size\"] >= 20)].copy()\n",
    "            list_ECs = df_EC.community.tolist()\n",
    "        #a questo punto, abbiamo solo gli utenti nelle EC\n",
    "            df_EC_users = df_users[df_users['community'].isin(list_ECs)].copy()\n",
    "            \n",
    "            print(df_EC_users.community.unique())\n",
    "            \n",
    "            df_EC_users[\"EC\"] = ec_val\n",
    "            ec_users = df_EC_users[[\"user_id\", \"EC\", \"max_label\"]].copy()\n",
    "            ec_users.to_csv(os.path.join(src_results, f\"{topic}/{ec_val}_user_TM_{topic}_{i}.csv\"), index = False)\n",
    "            \n",
    "            comments = list()\n",
    "            list_temp_df = []\n",
    "            period0 = datetime.datetime.strptime(sem[0], \"%d/%m/%Y\").strftime(\"%d-%m-%Y\")\n",
    "            period1 = datetime.datetime.strptime(sem[1], \"%d/%m/%Y\").strftime(\"%d-%m-%Y\")\n",
    "            # retrieve raw text comments from users' json files\n",
    "            semester_user_comments = os.path.join(f'../topic_comments/{topic}/{topic}_{period0}_{period1}/')\n",
    "            json_files = [pos_json for pos_json in os.listdir(semester_user_comments) if pos_json.endswith('.json')]\n",
    "            for f in json_files:\n",
    "                f = load_json(os.path.join(semester_user_comments, f))\n",
    "                df = pd.json_normalize(f[\"comments\"],max_level=1)\n",
    "                list_temp_df.append(df)\n",
    "            df_text_users = pd.concat(list_temp_df)\n",
    "\n",
    "            if topic == \"minority\" and i == 4: \n",
    "                df_text_users.clean_text.fillna(df_text_users['body'], inplace=True)\n",
    "                del df_text_users[\"body\"]\n",
    "            elif \"body\" in df_text_users.columns:\n",
    "                df_text_users[\"clean_text\"] = df_text_users[\"body\"]\n",
    "                del df_text_users[\"body\"]\n",
    "                  \n",
    "            df_final_users = pd.merge(left=df_EC_users[[\"community\", \"user_id\"]], right = df_text_users, left_on=\"user_id\", \n",
    "                                      right_on = \"author\" , how = \"inner\")\n",
    "        \n",
    "\n",
    "            # structure of the final df\n",
    "            # useraname | subreddit in which the comment appears | timestamp | category | text | post (bool) | commento (bool) | stats \n",
    "            df_final_users.to_csv(os.path.join(f\"../text_data/comments/{topic}/{ec_val}_comments_{topic}_{i}.csv\"), index = False)\n",
    "            \n",
    "            i+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_comments(categories, \"EC\")\n",
    "preprocess_comments(categories, \"not_EC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_posts(cat, ec_val):\n",
    "    data_path = f\"../topic_posts/\" \n",
    "    for topic in tqdm(categories):\n",
    "        i = 0\n",
    "        for sem in semesters:\n",
    "            print(\"Current iteration:\", i)\n",
    "        # prendiamo il df delle EC per vedere l'id delle community EC\n",
    "            df_community = pd.read_csv(os.path.join(src_results, f\"{topic}/{ec_val}/{ec_val}_{topic}_{i}.csv\"))\n",
    "        #prendiamo il df degli utenti nelle community\n",
    "            df_stats = pd.read_csv(os.path.join(src_results, f\"{topic}/eva_users_merged_{i}_com_stats.csv\"))\n",
    "            df_users = df_stats\n",
    "            coms_list = df_community.community.tolist()\n",
    "            df_EC_users = df_users[df_users['community'].isin(coms_list)].copy()\n",
    "            ec_users = df_EC_users[[\"user_id\", \"max_label\"]].copy()\n",
    "            ec_users.to_csv(os.path.join(src_results, f\"{topic}/{ec_val}_user_TM_{topic}_{i}.csv\"), index = False)\n",
    "            \n",
    "            # the text data were previously cleaned\n",
    "            period0 = datetime.datetime.strptime(sem[0], \"%d/%m/%Y\").strftime(\"%d-%m-%Y\")\n",
    "            period1 = datetime.datetime.strptime(sem[1], \"%d/%m/%Y\").strftime(\"%d-%m-%Y\")\n",
    "            filename = os.path.join(data_path, f'{topic}/{topic}_{period0}_{period1}.csv')\n",
    "            df_post = pd.read_csv(filename)\n",
    "            df_filtered_post = df_post[df_post[\"author\"].isin(df_EC_users[\"user_id\"].tolist())].copy()\n",
    "            df_final = pd.merge(left=df_EC_users[[\"community\", \"user_id\"]], right = df_filtered_post, left_on=\"user_id\", \n",
    "                    right_on = \"author\" , how = \"inner\")\n",
    "\n",
    "            df_final[\"EC_val\"] = ec_val\n",
    "            df_final.to_csv(os.path.join(f\"../text_data/posts/{topic}/{ec_val}_post_{topic}_{i}.csv\"), index = False)\n",
    "            i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_posts(categories, \"EC\")\n",
    "preprocess_posts(categories, \"not_EC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_post_text_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m preprocess_post_text_pipeline(categories, \u001b[39m\"\u001b[39m\u001b[39mnon_EC\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_post_text_pipeline' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
